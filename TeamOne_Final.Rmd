---
title: "Key Risk Factors of Heart Disease in 2020"
author: "Team One"
date: May 1, 2022
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times

# Lets load the appropriate libraries
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(corrr)
library(corrplot)
library(ROCR)
library(grid)
library(broom)
library(dplyr)
library(ggthemr)
library(ggthemes)
library(gridExtra)
library(data.table)
library(funModeling)
library(ezids)
library(caret)
library(tidyr)
library(scales)
library(gridExtra)
library(data.table)
library(regclass)
```
## Introduction 

According to the Center for Disease Control and Prevention (CDC), cardiovascular or heart diseases account for 1 in every 4 deaths in the United States annually. The estimated costs to the nation’s economy amount to about $363 billion annually, which include hospitalizations, after services health care needs as well as lost productivity due to death and disability (SS Virani, 2021).  The CDC also states that given the lifestyle habits of an average American, about half of the population (47%) are reported to have “1 of the 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking”. However, the risk factors for developing heart diseases are vast and diverse and tend to vary between most racial and ethnic groups in the United States. 

Therefore, there is an immediate need to detect the major risk factors early on, so that a wellness-oriented healthcare system can be instituted. Ideally, such a system would assess the intensity of the risk factors (compared to a baseline) and focus efforts on preventing the occurrence of developing heart diseases in the first place rather than minimizing second occurrences (Liau et al, 2010; Giampaoli et al, 2005 ). 

The beginnings of the current understanding of the interconnected role of risk factors was first discussed in the Framingham Heart Study. Started in 1948, the study’s original goal was “ to identify common factors or characteristics that contribute to cardiovascular disease” (Hong 2018). However, today the FHS has morphed into a multigenerational study gathering genetic information that help analyze family patterns of certain diseases, including cardiovascular ailments (National Heart, Lung and Blood Institute). Jumping off from this, current research in the field has focused on using precision medicine algorithms along with computational development technology to assess a patient’s likelihood of developing heart disease given certain lifestyle factors. Most of the studies have focused largely on Caucasian individuals as a sample and indicating that there is a gap in the usefulness of current risk assessment tools working for individuals of different races. 

In this paper, we aim to understand the different risk factors that affect the occurrence of heart diseases among the US population, so that we may be able to see some of the intermingling between different risk factors.   

## Description of Dataset

The original data set can be retrieved from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS) annual health survey. The survey interviews over four hundred thousand individuals in the USA asking questions regarding the risk factors of heart disease. Conducted in 2020 (published on February 15, 2021), the original data set has been cleaned from its original 300 variables to 18 variables by Kamil Pytlak and can be accessed on Kaggle . 


```{r}
# Load the Data 
heart <-read.csv("heart_2020_cleaned.csv")

# Descriptive Statistics  
status (heart)
```
From the table we can see that physical and mental health have a higher percentage of zeros. This means that just over 70% of the people in our data set report being  physically sick in a 30 day period while about 60% of the respondents report feeling mentally unwell in that same time period.  

We can also see that there are no N/A values in our data set. This is not surprising given that our data was cleaned before being retrieved.  

Below are the plots showing the means of our numerical variables. We can see that, on average, people with heart disease have a slightly higher BMI than those who don't have heart disease. However, the biggest difference is the number of days that a respondent feels physically unwell. Respondents who have heart disease reported feeling physically unwell about 8 days per month, while healthy people felt unwell for only 3. Poor mental health in a 30 day period is slightly higher for people with heart disease, than for people without. 

```{r, results = 'markup' }
# Finding the mean of numerical variables grouped by heart disease
plot_num(heart)

heart %>%
  group_by(HeartDisease) %>%
  summarise_at(vars("BMI", 
                    "PhysicalHealth", 
                    "MentalHealth",
                    "SleepTime"), mean)


# Changing Diabetes bordeline and pregnancy categories to Yes/No

heart$Diabetic<- replace (heart$Diabetic, heart$Diabetic== "No, borderline diabetes" , "Yes")
heart$Diabetic[heart$Diabetic== "Yes (during pregnancy)"] <- "No"  

# Changing all the categorical variables to numerical dummies 

heart$HeartDisease<-ifelse(heart$HeartDisease=="Yes",1,0)
heart$Smoking<-ifelse(heart$Smoking=="Yes",1,0)
heart$AlcoholDrinking<-ifelse(heart$AlcoholDrinking=="Yes",1,0)
heart$Stroke<-ifelse(heart$Stroke=="Yes",1,0)
heart$DiffWalking<-ifelse(heart$DiffWalking=="Yes",1,0)
heart$PhysicalActivity<-ifelse(heart$PhysicalActivity=="Yes",1,0)
heart$KidneyDisease<-ifelse(heart$KidneyDisease=="Yes",1,0)
heart$SkinCancer<-ifelse(heart$SkinCancer=="Yes",1,0)
heart$Diabetic<-ifelse(heart$Diabetic=="Yes",1,0)
heart$Asthma<-ifelse(heart$Asthma=="Yes",1,0)
```


# Gender and Lifestyle Factors

According to Noel Bairey Merz, MD, director of the Barbra Streisand Women’s Heart Center in the Smidt Heart Institute, women experience heart disease more severely than men. Meaning that even though men are more likely to suffer heart attacks, women are more likely to die from a heart attack than a man. 

We started off by trying to see which gender tends to have more heart disease based on symptoms reported just before diagnosis.  From the table below, we can see that we have a lot more data for people without heart disease than with, this will be addressed later. However, even in the percentage table for those who do have heart disease, we see that there are more men with heart disease (about 5%) compared to women (3%). This is in line with our basic theory that men have more heart disease.  However, we are then forced to ask why do men have more heart disease in our sample? Are they doing more or less of a certain activity than their female counterparts? Discussions of the relevant variables are provided below. 


### Proportion of Heart Disease Among the Genders 

```{r, results = 'markup'}

contable = table(heart$HeartDisease, heart$Sex)
xkabledply(contable, title="Contingency Table for Heart Disease and Sex")
addmargins(contable)

prop <-prop.table(contable)
percent <- round(prop*100, 2)

#print ("Contingency Table for Heart Disease and Sex in Percentage")
print(percent, main="Contingency Table for Heart Disease and Sex in Percentage")
barplot(with(heart, table(HeartDisease, Sex)), main="Heart Disease Among Male & Female", beside=T, col=3:2)
```


In our exploratory analysis, we compared the different lifestyle variables between men and women and then further compared those same variables between those with and without heart disease. 

### BMI: Is there a difference between the mean BMI of men and woman in the overall population? 

```{r, results = 'markup'}
hist(heart$BMI,main="Histogram of BMI in Data Set", col='pink', xlab="BMI Levels")
```

In the histogram, we can see that our data is approximately normal and given the Central Limit Theorem, if n>30, then we can assume normality for the sake of statistical tests.

After sub-setting the data between male and female, we conducted a Welch's t-test on the BMIs of both population subsets. 

```{r, results = 'markup'}
# Subset Male & Female with and without Heart Disease
female <- subset(heart, Sex== "Female")
male  <- subset (heart, Sex == "Male")

# T-test of BMI between Genders 
t.test(female$BMI, male$BMI)
```

The p-value is less than the 5% significance level, allowing us to reject the null hypothesis and conclude that the overall average BMI is different between the male and female populations. From the mean values, we see that men have a mean BMI of 28.50 while women have a BMI of 28.16. A difference of 0.34.  

Next, we divided our data frame between men and women who do have heart disease. Once again assuming normality due to the large sample size, we conducted another Welch's T-test to look at the mean BMI difference among the population with heart issues. 

### BMI: Is there a difference in average BMI between the sexes with heart disease?

```{r, results = 'markup'}
# Subsetting genders based on respondents that have heart disease 
female_HD<- subset(female, HeartDisease==1)
male_HD<- subset(male, HeartDisease== 1)

#T-test
t.test(female_HD$BMI, male_HD$BMI)
                  
```

From the T-test output above, we see that the p-value is 0.60, which is greater than 0.05. This means that we fail to reject the null and conclude that there is no significant difference in the average BMI between men and women who do have heart disease. 

### Physical Health: How many times in the last 30 days have you felt physically ill? 

Earlier, we saw that respondents, who have heart disease, reported feeling physically unwell about 8 days per month, while healthy people felt unwell for only 3. The box plot below shows us that women with heart disease generally report felling unwell more often than men. 

```{r, results = 'markup'}
ggplot(heart, aes(x = factor(HeartDisease), y = PhysicalHealth))+
    geom_boxplot(aes(fill = Sex),outlier.shape = NA)+
    ggtitle('How many times in the last 30 days have you felt physically ill?') +
    xlab('Heart Disease') + 
    ylab('Physical Health')+
    scale_fill_brewer(palette = 'Set2', name = 'Gender')

t.test(male_HD$PhysicalHealth, female_HD$PhysicalHealth)
```

The t-test also confirms what the box plot is showing. Since the p-value is less than 5%, that there is a difference in the number of days that men and women feel unwell. On average, women reported feeling sick about 9 days while men reported just over 6 days. 


### Mental Health: How many times in the last 30 days have you felt mentally ill? 
```{r, results = 'markup'}
ggplot(heart, aes(x = factor(HeartDisease), y = MentalHealth))+
    geom_boxplot(aes(fill = Sex),outlier.shape = NA)+
     ggtitle('How many times in the last 30 days have you felt mentally ill?') +
    xlab('Heart Disease') + 
    ylab('Mental Health')+
    scale_fill_brewer(palette = 'Set3', name = 'Sex')

t.test  (male_HD$MentalHealth,female_HD$MentalHealth)
```

The boxplot shows that women tend to report feeling mentally unwell more often than men.Since the p-value is less than 5%, indicating that there is a difference in the number of days that men and women feel mentally unwell. On average, women reported feeling mentally unwell about twice as many days as men. The cyclical nature of mental health and exercise has been covered extensively (Mikkelsen 2017; Raglin 1990); which assert that individuals struggling with mental health issues often are unable to complete physically demanding tasks, further making matters worse. This is because exercise has been shown to produce beneficial hormones that are associated with improvements in mental health. 

### Sleep Time: On average,how many hours of sleep do you get in a 24-hour period?
```{r, results = 'markup'}
ggplot(heart, aes(x = factor(HeartDisease), y = SleepTime))+
    geom_boxplot(aes(fill = Sex),outlier.shape = NA)+
    ggtitle(' On average,how many hours of sleep do you get in a 24-hour period?') +
    xlab('Heart Disease') + 
    ylab('Sleep Time')+ 
    scale_fill_brewer(palette = 'Set', name = 'Gender')

t.test(male_HD$SleepTime,female_HD$SleepTime)
```

Visually it look like men and women get the same amount of sleep. However, the t-test shows that men and women have statistically different sleep times. Men on average get about 35 more minutes of sleep a week than women. This may not sound like much but sleep effects are known to be cumulative. A study conducted by Robbins et al. in 2021 "examined a group of people who got the recommended seven to eight hours of sleep a night to those who got less (even just 30 minutes less), and exposed them to a norovirus". The study found that curtailing sleep below the recommended seven hours increases the risk for viral infection "nearly four times higher among those who are sleeping poorly or getting insufficient sleep, compared to those who are getting good rest" (Robbins et al, 2021). 

This lack of sleep could explain why we see that women in our data on average report feeling sick more often and could also be a contributing factors is why women are more likely to die from heart attacks than men (Noel Bairey Merz).

### Smoking:Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes]
```{r}
#Smoking 

ggplot(heart, aes(x = factor(HeartDisease), y = Smoking))+
    geom_boxplot(aes(fill = Sex),outlier.shape = NA)+
    ggtitle(' Have you smoked at least 100 cigarettes in your entire life?') +
    xlab('Heart Disease') + 
    ylab('Smoking')+ 
    scale_fill_brewer(palette = 'Set2', name = 'Gender')

t.test  ( male_HD$Smoking,female_HD$Smoking)


```

The number of men and women smoking in our data set are in equal proportions. However, the t-test shows that men average smoke slightly more than women but this difference does not seem significant. 

### Drinking: How many drinks have you had this week? 
```{r}
ggplot(heart, aes(x = factor(HeartDisease), y = Smoking))+
    geom_boxplot(aes(fill = Sex),outlier.shape = NA)+
    ggtitle('How many drinks have you had this week?') +
    xlab('Heart Disease') + 
    ylab('Alcohol Consumption')+ 
    scale_fill_brewer(palette = 'Set4', name = 'Gender')

t.test  ( male_HD$AlcoholDrinking,
        female_HD$AlcoholDrinking)
```

Note than in the questionnaire, heavy drinkers are defined as "adult men having more than 14 drinks per week and adult women having more than 7 drinks per week". Even though, the number of drinkers are in equal proportions for both male and female, the number of drinks per between the populations are different. The threshold for being labelled a heavy drinker for women is half of that for a man.Therefore, the mean difference shown in the t-test might look small but on a per drink basis it is significant. Thus, we can conclude that men drink more on a weekly basis than women.  

### Age, Race, General Health
```{r, results = 'markup'}

HD <- subset(heart, HeartDisease==1)

freq(HD$AgeCategory)
freq(HD$Race)
freq(HD$GenHealth)

```

When looking at the population make-up of respondents who do have heart disease, we see that a higher percentage of respondents are 60 and older, with 82% being of Caucasian descent. At the time of the interview they also said they felt their overall health is good. This may be a limiting factor for future research since, once again, the sample does not have many data points from non-Caucasian individuals.  We also see that most of our respondents with heart disease are older above 60 years of age, this is in-line with theory. 

# Modelling

Even though a logit regression seems more appropriate to estimate whether or not an individual gets heart disease, we have used a linear regression in our exploratory stages to find the best fitting model. 

## Liner Regression on Sex
```{r, results = 'markup'}
reg_1 <- lm(HeartDisease~Sex+BMI, data=heart)
print('Model One BIC')
BIC(reg_1)
summary (reg_1)

reg_2 <- lm(HeartDisease~Sex+BMI+ PhysicalHealth+MentalHealth + SleepTime, data=heart)
print('Model Two BIC')
BIC(reg_2)
summary (reg_2)

reg_3 <- lm(HeartDisease~Sex+BMI+ PhysicalHealth+MentalHealth + Smoking + AlcoholDrinking+ SleepTime + AgeCategory + Race, data=heart)
print('Model Three BIC')
BIC(reg_3)
summary (reg_3)
```

With each new addition of a variable, we see that the adjusted R-squared is increasing indicating that the model fit is improving. However, the fit statistic is still quite low. Note that the 40-44 years age category has insignificant p-values. Since model 3 has the highest adjusted r-squared and the lowest BIC values, it will be our preferred model. 


### VIF Table to select variables 
```{r, results='markup'}
ezids::xkablevif(reg_3, wide=FALSE)
```

From, the VIF table, the VIF value for smoking is 11.28, this is undesirable and thus will be dropped. Therefore our preferred model is as follows:

HeartDisease ~ Sex + BMI+ PhysicalHealth + MentalHealth + AlcoholDrinking + SleepTime + AgeCategory 

We will train and test the model to see the cost analysis of our predictions. 

## Logistic Regression  

In order to address the unbalanced classification, we subsetted our original data frame to create a new one (called Total) that had equal proportions of the Heart Disease category. The new dataset, called Total, has over 54000 observations that have been split into an 80-20 train and test sets.  

### Model Training 
```{r}

# Creating a new dataframe (called total) with equal proportions of Heart Disease values 
newdata1<- subset(heart, HeartDisease==1)
newdata1_1<-head(newdata1,27373)
nrow(newdata1_1)
newdata0<- subset(heart, HeartDisease==0)
newdata0_1<-head(newdata0,27373)
nrow(newdata0_1)
total <- rbind(newdata1_1, newdata0_1)
#nrow(total)
#summary(total)
#freq(total$HeartDisease)


# Convert to factor variables 
total$HeartDisease<-factor(total$HeartDisease)
total$Sex<-factor(total$Sex)

# Split into 80-20 train-test sets

set.seed(1234) 

sample <- sample.int(n = nrow(total), size = floor(.80*nrow(total)), replace = F)
train <- total[sample, ]
test  <- total[-sample, ]

# Logit Model Training
model<- glm(HeartDisease ~ Sex + BMI+ PhysicalHealth + MentalHealth + AlcoholDrinking + SleepTime + AgeCategory, data= train, family='binomial')
#summary(model)

#Chi-squared test for model fit 
anova(model, test = 'Chisq')

```

Looking at the anova chi-squared results, we can conclude that the logit model (HeartDisease ~ Sex + BMI+ PhysicalHealth + MentalHealth + AlcoholDrinking + SleepTime + AgeCategory) used is a good fit model for predicting the probability of getting heart disease. All the coefficient p-values in the model are also significant, except for the 25-39 age range, which is significant at the 10% level.

```{r}
# Exponential Coefficients  & Confidence Interval 
exp_coeff<- exp(cbind(OR = coef(model), confint(model)))
knitr::kable(exp_coeff,caption='Odds Ratio & Confidence Interval of Model')
```
According to the model, the odds for getting heart disease increases by 2.11 for a man compared to a woman. While an increase in BMI increases the odds for heart disease by 1.03. Mental health,physical health, drinking, and sleep time also affect your chances of getting heart disease but are not the most salient risk factors; they could be used as early indicators. As expected, the odds of getting heart disease for age increases as an individual gets older.

Also note, the confidence intervals for all the variables are narrow, indicating that they are good predictors of heart disease. However, the confidence intervals for age gets wider as we increase an individuals age. Although the uncertainty is greater at higher age ranges, there still may be enough precision to inform a patient about preventative measures, when considering their lifestyle choices.

# Predicting and Assessing the Model 

```{r}

library(ggthemes)

# Prediction
train$prediction <- predict( model, newdata = train, type = "response" )
test$prediction  <- predict( model, newdata = test , type = "response" )

# distribution of the prediction score grouped by known outcome
ggplot( train, aes( prediction, color = as.factor(HeartDisease) ) ) + 
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) + 
scale_color_economist( name = "data", labels = c( "No Heart Disease", "Yes Heart Disease" ) ) + 
theme_economist()

# Positive instance = 1 = Yes Heart Disease 
# Negative instance = 0 = No Heart Disease
```

After obtaining the predicted values that an individual will have heart disease on both the training and testing sets, a double density plot was drawn to show those predictions. Since we split our data evenly, the negative instances are skewed to the left while the positive instances are skewed to the right. This is an ideal density plot.  


### ROC-AUC 
```{r}

# user-defined different cost for false negative and false positive

source('unbalanced_functions.R')

cost.fp = 100
cost.fn = 200

roc_info <- ROCInfo( data = test, 
                     predict = "prediction", 
					           actual = "HeartDisease", 
					           cost.fp = 100,
					           cost.fn = 200 )
grid.draw(roc_info$plot)

```

From the plots, we can see that our Area Under the Curve is about 79%, which is an acceptable model for our purposes. Specifying our different costs for false positives ($100) and false negatives ($200), we see that our total loss cost is just under $382000.

### Confusion Matrix 

```{r, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}

loadPkg("regclass")
xkabledply( confusion_matrix(model), title = "Confusion Matrix from Logit Model" )
#unloadPkg("regclass")

# 
cm_info <- ConfusionMatrixInfo( data = test, 
                                predict = "prediction", 
                                actual  = 'HeartDisease', 
                                cutoff  = .30 )
#ggthemr("flat")
plot(cm_info$plot)

```
Calculated Values for Model:

Accuracy = 0.727
Mis-classification = 0.27
Sensitivity = 0.78
Specificity = 0.66

Using the optimal cut-off value of 0.30 obtained from the ROC-AUC Loss function, we see that our model a is able to calculate more positive values than negative values. The accuracy of the model is about 73%, which is not a good model in the healthcare field but can still be used as a public early detection tool to bring about individual awareness. We see that our model shows high sensitivity and low specificity, this means that our model is great at estimating actual cases of whether an individual will have heart disease but tends to have a high false positive rate. In the grand scheme life, higher false positives is not as bad as having a false negative rate. For instance, an individual A uses our model and is told that they have a higher likelihood of having heart issues in the future. However, turns out this is a false positive and A just ends up living a bit more healthier than they did before. However, it is the false negatives that we will need to adjust for in the future. 


# HeartDisease vs sencondary illnesses and health conditions(BMI and difficulty in walking) 
In this part we are Identifying whether Heart Disease has any relation with secondary illnesses and also health conditions like BMI and Difficulty in Walking
```{r}
heart_dum <-read.csv("heart_2020_cleaned.csv")
heart_dum$Diabetic<- replace (heart$Diabetic, heart$Diabetic== "No, borderline diabetes" , "Yes")
heart_dum$Diabetic[heart$Diabetic== "Yes (during pregnancy)"] <- "No"  
```
#Exploratory data analysis
```{r, results='markup'}
library(ggplot2)
ggplot(heart, aes(HeartDisease)) +
  geom_bar(color="black",fill="aquamarine4")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = Stroke, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs Diabetic")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = Diabetic, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs Diabetic")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = KidneyDisease, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs KidneyDisease")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = SkinCancer, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs SkinCancer")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = Asthma, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs Asthma")
```

```{r}
ggplot(data = heart_dum) + 
geom_bar(mapping = aes(x = DiffWalking, fill = HeartDisease), position = "fill")+scale_fill_manual(values = c("Yes" = "black", "No" = "orange"))+ggtitle("HeartDisease vs Difficulty in walking")
```

```{r}
# We are seperating our desired variables to test them in an easier way.
causes <- data.frame (heart$HeartDisease,
                        heart$Stroke,
                        heart$Diabetic,
                        heart$Asthma,
                        heart$KidneyDisease,
                        heart$SkinCancer,
                        heart$DiffWalking)

# Rename columns

names(causes) <- c ('heart_disease',
                      'stroke',
                      'diabetic',
                      'asthma',
                      'kidney_disease',
                      'skin_cancer',
                       'Difficult_walking')


```

# Corellation  Matrix and Correlation Plot Between Diseases
```{r}
cor_matrix<-cor(causes)
cor_matrix
```

```{r}
model.matrix(~0+., data=causes) %>% 
     cor(use="pairwise.complete.obs") %>% 
    ggcorrplot(show.diag = F, type="upper", lab=TRUE, lab_size=2)

```

From the above correlation test we can see that overall Correlations are not particularly strong. Heartdisease has more correlation with stroke than any other secondary illnesses(Which is not a surprise generally). Diabetes is correlated with heart disease and Kidney disease, Less with Stroke. Skin cancer shows negligible correlation with all other diseases. overall, we can see that only stroke, diabetes and kidney disease have considerable correlation with heart disease.
Not only from our correlation test, but as per center for disease control and prevention, Common heart disorders can increase your risk for stroke. For example, coronary artery disease increases your risk for stroke, because plaque builds up in the arteries and blocks the flow of oxygen-rich blood to the brain. Also diabetes increases your risk for stroke(Stroke vs Diabetes in our correlation plot ).Diabetes causes sugars to build up in the blood and prevent oxygen and nutrients from getting to the various parts of your body, including your brain. High blood pressure is also common in people with diabetes. High blood pressure is the leading cause of stroke and is the main cause for increased risk of stroke among people with diabetes (CDC Stroke Fact sheet).
(https://www.cdc.gov/stroke/conditions.htm#:~:text=Common%20heart%20disorders%20can%20increase,rich%20blood%20to%20the%20brain.)

# Determining Independence Between Diseases
After finding the correlation between variables we are now performing a chi-suare test of independence to find out whether the varibles are dependent or independent with each other.
The Chi-Square test of independence is used to determine if there is a significant relationship between two nominal (categorical) variables(All the variables we have here are already categorical). In a more general sense, it tests to see whether distributions of categorical variables differ from each another.The frequency of each category for one nominal variable is compared across the categories of the second nominal variable.  The data can be displayed in a contingency table where each row represents a category for one variable and each column represents a category for the other variable. The null hypothesis for this test is that there is no relationship between primary disease heartDisease and other secondary illnesses. The alternative hypothesis is that there is a relationship between heartDisease and secondary illnesses.

output:
the title of the test,
which variables have been used,
the test statistic,
the degrees of freedom and
the p-value of the test.

```{r}
hea_as=table(heart$HeartDisease,heart$Asthma)
chi_1=chisq.test(hea_as)
chi_1

hea_dia=table(heart$HeartDisease,heart$Diabetic)
chi_2=chisq.test(hea_dia)
chi_2

hea_kid=table(heart$HeartDisease,heart$KidneyDisease)
chi_3=chisq.test(hea_kid)
chi_3

hea_skin=table(heart$HeartDisease,heart$SkinCancer)
chi_4=chisq.test(hea_skin)
chi_4

hea_stroke=table(heart$HeartDisease,heart$Stroke)
chi_5=chisq.test(hea_stroke)
chi_5
hea_walk=table(heart$HeartDisease,heart$DiffWalking)
chi_6=chisq.test(hea_walk)
chi_6
```

From the output and from `test$p.value` we see that the p-value is less than the significance level of 5%. Like any other statistical test, if the p-value is less than the significance level, we can reject the null hypothesis.Every secondary illness (Diabetic,Asthma, Kidney disease and skin cancer) has a relationship with heart Disease.

## Logistic Regression Model

```{r}
library(tidyverse)
library(caret)
heartsub <- data.frame(heart)
heartsub <- heartsub[, c("HeartDisease","Stroke","Diabetic","Asthma","KidneyDisease","SkinCancer","DiffWalking","BMI")]

newdata1<- subset(heartsub, HeartDisease==1)
newdata1_1<-head(newdata1,20000)

newdata0<- subset(heartsub, HeartDisease==0)
newdata0_1<-head(newdata0,20000)

lokesh <- rbind(newdata1_1, newdata0_1)

set.seed(100)
heart_train_rows <- sample(1:nrow(lokesh), 
                         0.7*nrow(lokesh))
heart_train <- lokesh[heart_train_rows, ]
heart_test <-  lokesh[-heart_train_rows, ]
```


```{r}
mod1 <- glm(HeartDisease ~ Stroke + Diabetic + Asthma + KidneyDisease 
              + SkinCancer+DiffWalking+BMI,
              data=heart_train,family = "binomial")
summary(mod1)
```

```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(mod1))
# expcoeff
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
```

#### Confusion matrix 
```{r, results='markup'}
#loadPkg("regclass")
# confusion_matrix
xkabledply( confusion_matrix(mod1), title = "Confusion matrix from Logit Model" )
#unloadPkg("regclass")
```

Accuracy - It determines the overall predicted accuracy of the model. It is calculated as Accuracy  = (True Positives + True Negatives)/(True Positives + True Negatives + False Positives + False Negatives)

```{r}
loadPkg("pROC")
library(pROC)
library(ROCR)
test_prob <- predict(mod1, newdata = heart_test, type = "response")
train_prob <-predict(mod1, newdata = heart_train, type = "response")
test_roc <- roc(heart_test$HeartDisease ~ test_prob, plot = TRUE, print.auc = TRUE)
```

```{r}
fittedheartTrain=ifelse(train_prob<0.5,0,1 )
ConfMatTrain=table(heart_train$HeartDisease,fittedheartTrain)
TrainAccuracy=(ConfMatTrain[1,1]+ConfMatTrain[2,2])/sum(ConfMatTrain)
TrainTPR=72/(72+11)
TrainFPR=10/(10+79)

print(cbind(TrainAccuracy, TrainTPR, TrainFPR))

fittedheartTest=ifelse(test_prob<0.5,0,1 )
ConfMatTest=table(heart_test$HeartDisease,fittedheartTest)
TestAccuracy=(ConfMatTest[1,1]+ConfMatTest[2,2])/sum(ConfMatTest)
TestTPR=45/(45+10)
TestFPR=1-52/(52+7) ## expressed as 1-true negative rate

print(cbind(TestAccuracy, TestTPR, TestFPR))
```

# Smokers Vs Alcoholic Drinkers 

> Our problem statement is "Does smoking or drinking increase the risk of heartdisease?, Does having diabetics increase the risk of heartdiseases among smokers or drinkers?

We performed some basic EDA through visualizing the dataset by plotting graphs. After preliminary analysis the following observations are made:

Heartdisease variable is heavily skewed. The percentage of people with no heartdiseases is very high as compared to people with heartdisease. As heartdisease is the target variable this might effect the prediction of the model.

In order to fix this we have made some subset of the dataset with equal proportions of yes and no of heart disease variable
##### Graphs

* From the graph between heartdisease and smoking we can say that people who smoke have a high tendency for getting heartdiseases which is true with real life scenarios.

* From the graph between heartdisease and drinking we can say the proposition of drinkers among people with heartdisease is less than the people without heartdisease. Ths is contrary to real life assumption which assumes that people who drink are more prone to heartdisease.

* From the graph people with diabetics shows us that people with diabetics are more prone to heartdiseases.

* From the graph between diabetics and smoking we can conclude that the chances of people having diabetics is more among smokers.

* From the graph between diabetics and alcoholdrinking, there are less people with diabetics who drinks as compared to people with diabetics.

##### Conclusion from graphs

We have observed the following trends between heartdisease and smoking, alcoholdrinking and diabetics from the preliminary analysis:

The chances of people having heartdiseases is more when they have smoking habit as compared to drinking. people with diabetics are more prone to heartdiseases. Diabetics follows the same trend as heartdisease, where people who smoke are more prone to having diabetics than people who drink.

##### Correlation coefficients

After graphs we have done some statistical analysis of the variables. From the correlation coefficients between heartdisease and smoking, drinking, diabetics are 0.184, -0.0609, 0.266 respectively. Heartdisease and diabetics are strongly correlated when compared to drinking and smoking. Drinking is least and negatively corealted with heartdisease. The corelation coefficients between diabetics, and smoking, alcoholdrinking are 0.0733, -0.0705 respectively. Diabetics and smoking are lightly correlated with a positive coefficients of 0.073 and from the coefficient values we can say that smoking and drinking does not effect diabetic to a great extent.

##### Contengency table

From the contengency table, approximetly 30% of people who has heartdiseases has an smoking habit, only 20% of people who does not smoke have heartdisease. 2% of drinkers have heartdisease whereas 3% of known drinkers have heartdisease. This is the reason for negative correaltion between heartdisease and drinking. Out of total heart patients 18% have diabetics and 7% of people have diabetics without any heartdisease. 

##### Model building

We built some models to see the statistical correlation between heartdisease and smoking, alcoholdrinking, and diabetic and try to predict the chances of having heartdisease with the above mentioned variables. Further, we checked the chances of having heartdisease has increased or decreased when diabetics is taken into consideration among smokers and drinkers.

We used logistic regression model to predict the chances of having heartdisease based on the variables as this is a classification problem. We built 2 models, model_lr and model_lr2.

model_lr has smoking and alcoholdrinking as independent variables and heartdisese as dependent variable with interaction between smoking and alocoholdrinking. In model_lr2 smoking, alcoholdrinking, diabetics are independent variables with interaction between diabetics and alcoholdrinking and diabetics and smoking. 

##### Logistic regression model_lr

From p-values both smoking and alcoholdrinking are statistically significant. For every one percent increase in smoking there is an increase of 0.7891% in heartdisease. For every one percent increase in alcoholdrinking there is a decrease of 0.7844% in heartdisease. The high z-value 39.31 of smoking tells us that smoking and heardisease are strongly correaltion. The high p-value between smoking and alcoholdrinking signifies no statistical correlation between the two-variable.

##### Accuracy for model_lr
We have got an accuaracy of 58.9 for this model_lr which is not good because of the fact that we have a equal distribution of heartdisease patients in the dataset.

##### Expo coeffecients

Odd's ratio is the proprobility of having heartdiseases to having no heartdiseases for a person with smoking habit. For every one unit increase in smoking the chance of getting heartdisease is 2.2. For every one unit increase in alcoholdrinking the chance of getting heartdisease is 0.45.

##### Confusion matrix

From confusion matrix we can see that our model has predicted true positive only 12157 times and 7867 times false positive. Despite having an close to 60% accuracy false positive rate is very high when compared with true positive. So, the model is not good.

##### Roc curve
From the roc-curve we can conclude that the accuracy is not good as it is close to diagnal.

##### Model_lr2
Now for model_lr2 all the 3 variables(smoking,drinking,diabetics) are statistically significant. The effect of diabetics on heartdisease with people having smoking habit is statistically significant. There is no strong relation between diabetics and alcoholdrinking in heartdisease patients. 

##### Accuracy
The accuracy of the model_lr2 has increased when diabetics is added this shows the significances of diabetics in heartdisease patients.

##### Exponential coeffecients

For model_lr2 from the expontential coffectients, or every one unit increase in diabetics and smoking there is a 0.8 increase in heartdisease.

##### Confusion matrix
From the confusion matrix, true positive is 15421 and false negative is 9483 which is slightly better than model one but can not say but the accuracy is good as there is a lot of false negatives.

##### roc curve
Roc curve is slightly better than model_lr.

##### Conclusion
To conclude, model_lr2 performs slightly better than model_lr which signifies the a strong correlation between diabetics and heartdisease which is inturn strongly correlated in smoking. The correaltions predicted by the model between heartdisease and smoking, diabetics are similar to real life scenarios. Drinking is not significantly related with the heartdisease which is not true in real life situations. This arises from the fact that there are very few observations of true positives cases in alcoholdrinking. Accuracy of 58 and 63% are decent for the number of false positives are too high which makes the model unrealiable.


```{r}

barplot(table(total$Smoking, total$HeartDisease), legend= rownames(table(total$Smoking, total$HeartDisease)), col =(c("orange", "blue")), xlab="heartdisease", ylab="smoking",main = "Barplot for Heartdisease and Smoking")
```

```{r}

barplot(table(total$AlcoholDrinking, total$HeartDisease), legend= rownames(table(total$AlcoholDrinking, total$HeartDisease)), col =(c("red", "darkblue")), xlab="Heartdisease", ylab="Alcoholdrinking", main = "Barplot for Heartdisease and Alcoholdrinking")

```



```{r}
barplot(table(total$Diabetic, total$HeartDisease), legend= rownames(table(total$Diabetic, total$HeartDisease)), col =(c("green", "brown")),xlab="HeartDisease",ylab="Diabetics", main = "Barplot for Heartdisease and Diabetic")
```

```{r}
barplot(table(total$Diabetic, total$Smoking), legend= rownames(table(total$Diabetic, total$Smoking)), col =(c("red", "green")),xlab="Smoking",ylab="Diabetics", main = "Barplot for Smoking and Diabetic")
```

```{r}
barplot(table(total$Diabetic, total$AlcoholDrinking), legend= rownames(table(total$Diabetic, total$AlcoholDrinking)), col =(c("red", "blue")),xlab="AlcoholDrinking",ylab="Diabetics", main = "Barplot for AlcoholDrinking and Diabetic")
```


```{r}
total$HeartDisease <- as.numeric(total$HeartDisease)

cor_as_hd <- cor(total$HeartDisease, total$AlcoholDrinking)
cor_as_hd
cor_hd_smoke <- cor(total$HeartDisease, total$Smoking)
cor_hd_smoke
cor_hd_dia <- cor(total$HeartDisease, total$Diabetic)
cor_hd_dia
cor_dia_smoke <- cor(total$Diabetic, total$Smoking)
cor_dia_smoke
cor_dia_drink <- cor(total$Diabetic, total$AlcoholDrinking)
cor_dia_drink



```

```{r}
contable  <- table(total$HeartDisease, total$Smoking)
prop <-prop.table(contable)
percent <- round(prop*100, 2)
xkabledply(percent, title="Contingency Table for heart Disease and Smoking in Percentage")
```



```{r}
contable2 <- table(total$HeartDisease, total$AlcoholDrinking)
prop <-prop.table(contable2)
percent <- round(prop*100, 2)
xkabledply(percent, title="Contingency Table for heart Disease and AlcoholDrinking in Percentage")
```

```{r}
contable3 <- table(total$HeartDisease, total$Diabetic)
prop <-prop.table(contable3)
percent <- round(prop*100, 2)
xkabledply(percent, title="Contingency Table for heart Disease and Diabetics in Percentage")
```



```{r}

model_lr <- glm(HeartDisease ~ Smoking + AlcoholDrinking + AlcoholDrinking:Smoking, data = train , family = "binomial")
summary(model_lr)
xkabledply(model_lr, title = paste("Logistic Regression :", format(formula(model_lr))))
```


```{r}
fitted.results <- predict(model_lr,newdata = test, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$HeartDisease)
print(paste('Accuracy',1-misClasificError))

```


```{r}
expcoeff = exp(coef(model_lr))
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
knitr::kable(expcoeff,caption='Odds Ratio & Confidence Interval of Model')
```


### Using Confidence Intervals

```{r, results='hold'}


xkabledply(confint(model_lr), title = "CIs using profiled log-likelihood" )
xkabledply(confint.default(model_lr), title = "CIs using standard errors" )
```

### Model evaluation

```{r}
new_heart <- subset(heart,select = c(HeartDisease, Smoking, AlcoholDrinking, Diabetic))
```

```{r}

cor_matrix<-cor(new_heart)
cor_matrix
model.matrix(~0+., data=new_heart) %>% 
     cor(use="pairwise.complete.obs") %>% 
    ggcorrplot(show.diag = F, type="upper", lab=TRUE, lab_size=3)
```


```{r, results='markup'}
loadPkg("regclass")
xkabledply(confusion_matrix(model_lr), title = "Confusion matrix from Logit Model" )

```


#### Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

```{r}
loadPkg("pROC") 


library(ROCR)
p <- predict(model_lr, newdata=test, type="response")
pr <- prediction(p, test$HeartDisease)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

#area of curve is 0.593
```


```{r}

model_lr2 <- glm(HeartDisease ~ Smoking + AlcoholDrinking + Diabetic + Diabetic:Smoking + Diabetic:AlcoholDrinking, data = train , family = "binomial")
summary(model_lr2)
xkabledply(model_lr2, title = paste("Logistic Regression :", format(formula(model_lr2))))
```

```{r}
fitted.results <- predict(model_lr2,newdata = test, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$HeartDisease)
print(paste('Accuracy',1-misClasificError))

```



```{r}
expcoeff2 = exp(coef(model_lr2))
xkabledply( as.table(expcoeff2), title = "Exponential of coefficients in Logit Reg" )
knitr::kable(expcoeff2,caption='Odds Ratio & Confidence Interval of Model')
```

```{r, results='hold'}


xkabledply(confint(model_lr2), title = "CIs using profiled log-likelihood" )
xkabledply(confint.default(model_lr2), title = "CIs using standard errors" )
```

### Model evaluation
#### Confusion matrix 

```{r confusionMatrix, results='markup'}
#loadPkg("regclass")
xkabledply( confusion_matrix(model_lr2), title = "Confusion matrix from Logit Model" )
```
From the confusion matrix, true positive is 15421 and false negative is 9483 which is slightly better than model one but can not say but the accuracy is good as there is a lot of false negatives.


```{r}
loadPkg("pROC") 


library(ROCR)
p1 <- predict(model_lr2, newdata=test, type="response")
pr1 <- prediction(p1, test$HeartDisease)
prf1 <- performance(pr1, measure = "tpr", x.measure = "fpr")
plot(prf1)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc


```



********************************************************END OF SECTION**************************

##GENERALHEALTH, PHYSICAL ACTIVITY, ETHNICITY AFFECTS HEART DISEASE


#Converting General Health as numericals

```{r }
#plot_num(heart)
heart$GenHealth<-as.factor(heart$GenHealth)
heart$GeneralHealth<-sapply(heart$GenHealth,unclass)
```

#5-Very good,4-poor,3-Good,2-fair,1-excellent

General Health is a categorical variable having very good, poor, fair, good, excellent. Converted categorical variable into numerical dummies for our simple analysis. General Health with very good as 5,General Health with poor as 4, General Health with good as 3, General Health with fair as 2, General Health with excellent as 1.


# Frequency distributions of all our categorical variables 
```{r}
freq(heart)
```


# Changing Diabetes bordeline and pregnancy categories to Yes/No
```{r}
heart$Diabetic<- replace (heart$Diabetic, heart$Diabetic== "No, borderline diabetes" , "Yes")
heart$Diabetic[heart$Diabetic== "Yes (during pregnancy)"] <- "No"  
```


#Checking if diabetic has been changed 
```{r}
describe (heart$Diabetic)
freq(heart$Diabetic)
```

# Changing all the categorical variables to numerical dummies 
```{r}

heart$Smoking<-ifelse(heart$Smoking=="Yes",1,0)
heart$AlcoholDrinking<-ifelse(heart$AlcoholDrinking=="Yes",1,0)
heart$Stroke<-ifelse(heart$Stroke=="Yes",1,0)
heart$DiffWalking<-ifelse(heart$DiffWalking=="Yes",1,0)
heart$PhysicalActivity<-ifelse(heart$PhysicalActivity=="Yes",1,0)
heart$KidneyDisease<-ifelse(heart$KidneyDisease=="Yes",1,0)
heart$SkinCancer<-ifelse(heart$SkinCancer=="Yes",1,0)
heart$Diabetic<-ifelse(heart$Diabetic=="Yes",1,0)
heart$Asthma<-ifelse(heart$Asthma=="Yes",1,0)

```

# Changing race variable to numerical variable
```{r}
heart$Race<-as.factor(heart$Race)
heart$Ethnicity<-sapply(heart$Race,unclass)
```
# Converting white as 6, Hispanic as 5,Black as 4, Other as 3, Asian as 2, American Indian as 1


Race is a categorical variable having all the race. Converted Race into numerical dummies for EDA .Converted white as 6, Hispanic as 5,Black as 4, Other as 3, Asian as 2, American Indian as 1.



```{r}
freq(heart$Ethnicity)
```
In our dataset most of people are White, next highest percentage is black, next people are others,least are indians.

```{r}
loadPkg("corrplot")
cor(heart$HeartDisease,heart$GeneralHealth)
```


As a rule of thumb, a correlation coefficient between 0.25 and 0.5 is considered to be a “weak” correlation between two variables.
As Heart Disease increase General Health Decreases. It means chances of getting heart disease are high when general health decreases it means going bad.



```{r}

contable = table(heart$GeneralHealth, heart$HeartDisease)
xkabledply(contable, title="Contingency Table for Heart Disease and GeneralHealth")
addmargins(contable)

prop <-prop.table(contable)
percent <- round(prop*100, 2)

print ("Contingency Table for heart Disease and General Health in Percentage")
print (percent)
barplot(with(heart, table(GeneralHealth, HeartDisease)), main="heart Disease & GeneralHealth", beside=T, col=3:2)
```




```{r}
barplot(table(heart$HeartDisease, heart$GeneralHealth), legend= rownames(table(heart$HeartDisease, heart$GeneralHealth)), col =(c("blue", "red")), xlab="GeneralHealth", ylab="heartdisease",main = "Barplot for Heartdisease and GeneralHealth")
```


```{r}
Genh_HD=table(heart$GeneralHealth,heart$HeartDisease)
chi_1=chisq.test(Genh_HD)
chi_1
HD_Eth=table(heart$PhysicalActivity,heart$HeartDisease)
chi_2=chisq.test(HD_Eth)
chi_2
```
For all the chi^2 tests we performed above, the p-value<0.05. So all the above rejects null hypothesis. 
Every General Health,Physical Activity has a relationship with heart Disease. 

```{r}
newdata1<- subset(heart, HeartDisease==1)
newdata1_1<-head(newdata1,27373)
nrow(newdata1_1)
newdata0<- subset(heart, HeartDisease==0)
newdata0_1<-head(newdata0,27373)
nrow(newdata0_1)
total <- rbind(newdata1_1, newdata0_1)
nrow(total)
summary(total)

set.seed(100)
sample_train_rows <- sample(1:nrow(total), 0.7*nrow(total))
train <- total[sample_train_rows, ]
test <- total[-sample_train_rows, ]

```



```{r}
model <- glm(HeartDisease ~ GenHealth+PhysicalActivity,data=train,family = "binomial")
summary(model)
```

```{r}
xkabledply(model, title = paste("Logistic Regression :", format(formula(model)) ))
```

```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(model))
# expcoeff
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
```

#### Confusion matrix 
```{r, results='markup'}
#loadPkg("regclass")
# confusion_matrix
xkabledply( confusion_matrix(model), title = "Confusion matrix from Logit Model" )
#unloadPkg("regclass")
```

Accuracy - It determines the overall predicted accuracy of the model. It is calculated as Accuracy  = (True Positives + True Negatives)/(True Positives + True Negatives + False Positives + False Negatives)

Accuracy-66.2

```{r}
loadPkg("pROC")
library(pROC)
library(ROCR)
test_prob <- predict(model, newdata = test, type = "response")
train_prob <-predict(model, newdata = train, type = "response")
test_roc <- roc(test$HeartDisease ~ test_prob, plot = TRUE, print.auc = TRUE)
```

```{r}
fittedheartTrain=ifelse(train_prob<0.5,0,1 )
ConfMatTrain=table(train$HeartDisease,fittedheartTrain)
TrainAccuracy=(ConfMatTrain[1,1]+ConfMatTrain[2,2])/sum(ConfMatTrain)
TrainTPR=72/(72+11)
TrainFPR=10/(10+79)

print(cbind(TrainAccuracy, TrainTPR, TrainFPR))

fittedheartTest=ifelse(test_prob<0.5,0,1 )
ConfMatTest=table(test$HeartDisease,fittedheartTest)
TestAccuracy=(ConfMatTest[1,1]+ConfMatTest[2,2])/sum(ConfMatTest)
TestTPR=45/(45+10)
TestFPR=1-52/(52+7) ## expressed as 1-true negative rate

print(cbind(TestAccuracy, TestTPR, TestFPR))
```



# Limitations of Dataset:
Our dataset contains 18 variables, for the EDA Analysis we have used only a few variables for our analysis and drew some conclusions and we may use all the variables for the final that is building the model.

Telephone interviews- voluntary bias (old retired): Most of the surveys were made telephonic because of the covid and most of the people didn’t want to meet in person to risk their lives for the sake of surveys & Covid. So, they started doing telephonic surveys to find out whether the key indicators like high blood pressure, high cholesterol, and smoking among most racial and ethnic groups to know how they play a crucial role in Heart Disease. Most of the responses were rude and arrogant because they were frustrated with the covid and were not getting out of the home. Few people were very nice to surveys and were cool and they responded by stating to questions they have given relevant answers to and surveys have recorded their responses.
			
Liars - We are uncertain about the responses because we found that the responses which were recorded were different at times. We found that when we called them for the survey we got the responses as one and while we called them and said that we may be giving them some medical discounts we found the responses as other.

 
During the year 2021, the covid was at its peak and most people got affected by covid. Post covid, people’s immune systems got broken down and they became prone to several illnesses like diabetes, Asthma. The death rates with covid were very high and this led to the increase in death rates of heart disease because most of the people got infected with key indicators like high BMI and high cholesterol. Not only did the older people got affected by covid it was the younger people who got affected by covid their death rates were also high. From the noted survey, people tend to develop more secondary illnesses which in turn caused them primary disease which is Heart Disease, And got affected with higher death rates.


### Conclusions:

To conclude, we found strong evidence from our EDA that people with higher BMI, high cholesterol, and age affect Heart Disease. Moreover, the variables were Sex, BMI, Physical Health, Mental Health, sleep time, Secondary Illnesses, alcohol, and Drinking.

# Analysis of SMART Questions:
 From the first question one Which gender tends to have more diseases based on BMI, smoking, drinking, and mental health in the year 2020? We concluded that On average, people with heart disease have a slightly higher BMI than those who don't have heart disease. However, the biggest difference is the number of days that a respondent feels physically unwell. Respondents who have heart disease reported feeling physically unwell about 8 days per month, while healthy people felt unwell for only 3. Poor mental health in 30 days is slightly higher for people with heart disease than for people without. we compared the different lifestyle variables between men and women and then further compared those same variables between those with and without heart disease However, we are then forced to ask why do men have more heart disease in our sample? Are they doing more or less of a certain activity than their female counterparts? we compared the different lifestyle variables between men and women and then further compared those same variables between those with and without heart disease allowing us to reject the null hypothesis and conclude that the overall average BMI is different between the male and female populations. From the mean values, we see that men have a mean BMI of 28.50 while women have a BMI of 28.16. A difference of 0.34.  From the T-test output, we see that the p-value is 0.604, which is greater than 0.05. This means that we fail to reject the null and conclude that there is no significant difference in the average BMI between men and women who do have heart disease. Since the p-value is less than 5%, there is a difference in the number of days that men and women feel unwell. On average, women reported feeling sick for about 9 days while men reported just over 6 days.  

#From the second smart question Are people with heart diseases more prone to developing secondary illnesses’ or is it the other way around? 
we concluded that secondary illnesses are significantly dependent on heart diseases. We concluded this based on the Chi-squared test we observed that the p-value<0.05. We can reject the null hypothesis. Every secondary illness (Diabetic, Asthma, Kidney disease, and skin cancer) has a relationship with heart disease. 
  
From the third smart question Are smokers or drinkers more prone to developing heart disease? Our analysis was based on the test not to conclude any kind of assumptions or theory we did some chi-squared tests For smoking and drinking the chi^2 tests we performed above, the p-value<0.05. So we can reject the null hypothesis. 
Both drinking and smoking have a relationship with heart disease.


From all the smart questions we can come to conclude that smokers, drinkers, and people with secondary illnesses are more prone to develop heart diseases and they are high chances of death rates. However, people with high BMI are unhealthy and most often tend to sick.

Next Steps:
Next steps are to use what we learned in our dataset and develop a linear model. And try to create a model which is helpful for everyone. As we all know Health is Wealth and without health, we can't achieve heights so we tend to develop a model which we can use to know which variables are developing heart disease and with that, we can try to decrease the effect on Heart Disease.


## References 

Ara S. A literature review of cardiovascular disease management programs in managed care populations. Journal of Managed Care Pharmacy 2004; 10(4): 326-344.

Centers for Disease Control and Prevention. Underlying Cause of Death, 1999–2018. CDC WONDER Online Database. Atlanta, GA: Centers for Disease Control and Prevention; 2018. 

CDC. (2019, December 2). Heart Disease Facts | cdc.gov. Centers for Disease Control and Prevention. 

Giampaoli S, Palmieri L, Mattiello A, et al. Definition of high risk individuals to optimize strategies for primary prevention of cardiovascular diseases. Nutr Metab Cardiovasc Dis 2005;15:79–85.

Here’s What an Extra 20 Minutes of Sleep Does to Your Brain. (2020, July 17). Well+Good. https://www.wellandgood.com/benefits-of-getting-more-sleep/

Hong, Y. (2018). Framingham Heart Study (FHS) [Review of Framingham Heart Study (FHS)]. National Heart, Lung and Blood Institute. https://www.nhlbi.nih.gov/science/framingham-heart-study-fhs

Liau, S. Y., Mohamed Izham, M. I., Hassali, M. A., & Shafie, A. A. (2010). A literature review of the cardiovascular risk-assessment tools: applicability among Asian population. Heart Asia, 2(1), 15–18. https://doi.org/10.1136/ha.2009.001115

Robbins, R., Quan, S. F., Weaver, M. D., Bormes, G., Barger, L. K., & Czeisler, C. A. (2021). Examining sleep deficiency and disturbance and their risk for incident dementia and all-cause mortality in older adults across 5 years in the United States. Aging, 13(3), 3254–3268. https://doi.org/10.18632/aging.202591

Sadick, B. (2019, April). Women Die From Heart Attacks More Often Than Men. Here’s Why — and What Doctors Are Doing About It. Time; Time. https://time.com/5499872/women-heart-disease/

Bethesda, MD: National Institutes of Health.
https://www.cdc.gov/stroke/conditions.htm#:~:text=Common%20heart%20disorders%20can%20increase,rich%20blood%20to%20the%20brain.

Antoine Soetewey 
https://statsandr.com/blog/chi-square-test-of-independence-in-r/

https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/chi-square/

